# -*- coding: utf-8 -*-
"""IoT_Replication.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Olx8OC340jz4Bg6rjTAZHNbS4VfofB6Q
"""

!cp /content/drive/MyDrive/propotion.csv /content/dataset_13.csv

import pandas as pd
import numpy as np
import seaborn as sns

df=pd.read_csv('dataset_13.csv')#13 means going to make 13 features from 85 in dataset

print('Number of rows'+str(df.count()))
df.head()

ax=sns.countplot(df['Label'])
ax.set_xticklabels(labels=ax.get_xticklabels(),rotation=30)

df =df[~df.isin([np.nan, np.inf, -np.inf]).any(1)]

print('After removing nan instances, Now the number of rows is'+str(df.count()))

df.iloc[0:2,:30]

df.iloc[0:2,30:]

index_to_delete=df.columns.difference(['Flow IAT Mean','Flow Duration','Flow Packets/s','Flow IAT Max','Fwd Packet Length Max','Total Length of Fwd Packet','Fwd Packet Length Mean','Total Bwd packets', 'Fwd IAT Total','Flow IAT Std','Flow Bytes/s','Total Fwd Packet','Flow IAT Min','Label'])

print(index_to_delete)
print(index_to_delete.size)#13 features + 1 label so 14 removed from 85-14=> 71

df.drop(index_to_delete,axis=1,inplace=True)

df.iloc[0:3,:]

df=df.dropna()

df.drop(df.columns[0], axis=1,inplace=True)

X=df.iloc[:,:-1]
y=df['Label']

X.iloc[0:3,:]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)

from sklearn.naive_bayes import BernoulliNB

X_train.isna().any()

"""# 13 Features

"""

score_label=['Accuracy','Precision','Recall','F-Measure']

from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score

gnb=BernoulliNB().fit(X_train,y_train)
nb_predictions=gnb.predict(X_test)
print(accuracy_score(y_test,nb_predictions))

NB_score=accuracy_score(y_test,nb_predictions),precision_score(y_test,nb_predictions,average='macro'),recall_score(y_test,nb_predictions,average='macro'),f1_score(y_test,nb_predictions,average='macro')
NB_metrics=pd.DataFrame(data=[NB_score],columns=score_label)
print(NB_metrics)

from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA
qda=QDA().fit(X_train,y_train)
qda_predictions=qda.predict(X_test)
print(accuracy_score(y_test,qda_predictions))

QDA_score=accuracy_score(y_test,qda_predictions),precision_score(y_test,qda_predictions,average='macro'),recall_score(y_test,qda_predictions,average='macro'),f1_score(y_test,qda_predictions,average='macro')
QDA_metrics=pd.DataFrame(data=[QDA_score],columns=score_label)
print(QDA_metrics)

#ID3
from sklearn.tree import DecisionTreeClassifier
dt=DecisionTreeClassifier(criterion='entropy',splitter='best').fit(X_train,y_train)
dt_predictions=dt.predict(X_test)
print(accuracy_score(y_test,dt_predictions))

ID3_score=accuracy_score(y_test,dt_predictions),precision_score(y_test,dt_predictions,average='macro'),recall_score(y_test,dt_predictions,average='macro'),f1_score(y_test,dt_predictions,average='macro')
ID3_metrics=pd.DataFrame(data=[ID3_score],columns=score_label)
print(ID3_metrics)

from sklearn.neural_network import MLPClassifier
mlp=MLPClassifier(random_state=0,max_iter=300).fit(X_train, y_train)
mlp_predictions=mlp.predict(X_test)
print(accuracy_score(y_test,mlp_predictions))

MLP_score=accuracy_score(y_test,mlp_predictions),precision_score(y_test,mlp_predictions,average='macro'),recall_score(y_test,mlp_predictions,average='macro'),f1_score(y_test,mlp_predictions,average='macro')
MLP_metrics=pd.DataFrame(data=[MLP_score],columns=score_label)
print(MLP_metrics)

from sklearn.ensemble import AdaBoostClassifier
adbc=AdaBoostClassifier().fit(X_train,y_train)
adbc_predictions=adbc.predict(X_test)
print(accuracy_score(y_test,adbc_predictions))

ADBC_score=accuracy_score(y_test,adbc_predictions),precision_score(y_test,adbc_predictions,average='macro'),recall_score(y_test,adbc_predictions,average='macro'),f1_score(y_test,adbc_predictions,average='macro')
ADBC_metrics=pd.DataFrame(data=[ADBC_score],columns=score_label)
print(ADBC_metrics)

from sklearn.ensemble import RandomForestClassifier
rf=RandomForestClassifier().fit(X_train,y_train)
rf_predictions=rf.predict(X_test)
print(accuracy_score(y_test,rf_predictions))

RF_score=accuracy_score(y_test,rf_predictions),precision_score(y_test,rf_predictions,average='macro'),recall_score(y_test,rf_predictions,average='macro'),f1_score(y_test,rf_predictions,average='macro')
RF_metrics=pd.DataFrame(data=[RF_score],columns=score_label)
print(RF_metrics)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.neighbors import KNeighborsClassifier
# knn=KNeighborsClassifier(n_neighbors=10).fit(X_train,y_train)
# knn_predictions=knn.predict(X_test)
# print(accuracy_score(y_test,knn_predictions))

KNN_score=accuracy_score(y_test,knn_predictions),precision_score(y_test,knn_predictions,average='macro'),recall_score(y_test,knn_predictions,average='macro'),f1_score(y_test,knn_predictions,average='macro')
KNN_metrics=pd.DataFrame(data=[KNN_score],columns=score_label)
print(KNN_metrics)

"""# 7 Features

7 Features
"""

!cp '/content/drive/MyDrive/propotion_7.csv' feature_7.csv

df1=pd.read_csv('feature_7.csv')
df1 =df1[~df1.isin([np.nan, np.inf, -np.inf]).any(1)]
df1.head()
X1=df1.iloc[:,:-1]
y1=df1['Label']
X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, random_state = 0)

def print_full(x):
    pd.set_option('display.max_rows', None)
    pd.set_option('display.max_columns', None)
    pd.set_option('display.width', 2000)
    pd.set_option('display.float_format', '{:20,.2f}'.format)
    pd.set_option('display.max_colwidth', None)
    print(x)
    pd.reset_option('display.max_rows')
    pd.reset_option('display.max_columns')
    pd.reset_option('display.width')
    pd.reset_option('display.float_format')
    pd.reset_option('display.max_colwidth')

rf1=RandomForestClassifier().fit(X_train1,y_train1)
rf_predictions1=rf1.predict(X_test1)

RF_score1=accuracy_score(y_test1,rf_predictions1),precision_score(y_test1,rf_predictions1,average='macro'),recall_score(y_test1,rf_predictions1,average='macro'),f1_score(y_test1,rf_predictions1,average='macro')
RF_metrics1=pd.DataFrame(data=[RF_score1],columns=score_label)
print(RF_metrics1)

precision_rf7, recall_rf7, fscore_rf7, support_rf7=score(y_test1,rf_predictions1)
recall_table_rf7=pd.DataFrame(data=[recall_rf7],columns=['DDoS_HTTP', 'DDoS_TCP', 'DDoS_UDP', 'Data_Exfiltration','DoS_HTTP', 'DoS_TCP', 'DoS_UDP', 'Keylogging', 'OS_Scan','Service_Scan'])
print_full(recall_table_rf7)

gnb1=BernoulliNB().fit(X_train1,y_train1)
nb_predictions1=gnb1.predict(X_test1)
print(accuracy_score(y_test1,nb_predictions1))

NB_score1=accuracy_score(y_test1,nb_predictions1),precision_score(y_test1,nb_predictions1,average='macro'),recall_score(y_test1,nb_predictions1,average='macro'),f1_score(y_test1,nb_predictions1,average='macro')
NB_metrics1=pd.DataFrame(data=[NB_score1],columns=score_label)
print(NB_metrics1)

precision_nb7, recall_nb7, fscore_nb7, support_nb7=score(y_test1,nb_predictions1)
recall_table_nb7=pd.DataFrame(data=[recall_nb7],columns=['DDoS_HTTP', 'DDoS_TCP', 'DDoS_UDP', 'Data_Exfiltration','DoS_HTTP', 'DoS_TCP', 'DoS_UDP', 'Keylogging', 'OS_Scan','Service_Scan'])
print_full(recall_table_nb7)

"""Confusion matrix"""

from sklearn.metrics import confusion_matrix 
cm = confusion_matrix(y_test, gnb_predictions)

print(cm)

from sklearn.metrics import precision_recall_fscore_support as score
precision, recall, fscore, support = score( gnb_predictions,y_test)

print('precision: {}'.format(precision))
#print('recall: {}'.format(recall))
print('fscore: {}'.format(fscore))
#print('support: {}'.format(support))

ddos_http=df[df['Label']=='DDoS_HTTP']
ddos_tcp=df[df['Label']=='DDoS_TCP']
ddos_udp=df[df['Label']=='DDoS_UDP']
data_exfiltration=df[df['Label']=='Data_Exfiltration']
dos_http=df[df['Label']=='DoS_HTTP']
dos_tcp=df[df['Label']=='DoS_TCP']
dos_udp=df[df['Label']=='DoS_UDP']
keylogging=df[df['Label']=='Keylogging']
os_scan=df[df['Label']=='OS_Scan']
service_scan=df[df['Label']=='Service_Scan']

import gc
gc.collect()

from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import BernoulliNB
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score
from sklearn.metrics import classification_report
score_label=['Accuracy','Precision','Recall','F-Measure']

def NB_ml_model(df):
  X=df.iloc[:,:-1]
  y=df['Label']
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state = 13)
  gnb=BernoulliNB().fit(X_train,y_train)
  nb_predictions=gnb.predict(X_test)
  print(set(y_test))
  print(classification_report(y_test,nb_predictions,target_names=Labels))
  gc.collect()

def QDA_ml_model(df):
  X=df.iloc[:,:-1]
  y=df['Label']
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state = 13)
  qda=QDA().fit(X_train,y_train)
  qda_predictions=qda.predict(X_test)
  print(classification_report(y_test,qda_predictions,target_names=Labels))
  gc.collect()

Labels=['DDoS_HTTP', 'DDoS_TCP', 'DDoS_UDP', 'Data_Exfiltration','DoS_HTTP', 'DoS_TCP', 'DoS_UDP', 'Keylogging', 'OS_Scan','Service_Scan']
NB_ml_model(df)

QDA_ml_model(df)

def RF_ml_model(df):
  X=df.iloc[:,:-1]
  y=df['Label']
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state = 13)
  rf=RandomForestClassifier().fit(X_train,y_train)
  rf_predictions=rf.predict(X_test)
  print(classification_report(y_test,rf_predictions,target_names=Labels))
  gc.collect()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# RF_ml_model(df)

"""Data Visualization"""

!cp /content/drive/MyDrive/sampled.csv .

import pandas as pd
df=pd.read_csv('sampled.csv')
df.head(10)